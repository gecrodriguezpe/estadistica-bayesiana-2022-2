{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "constant-dubai",
   "metadata": {},
   "source": [
    "# Métodos de Monte Carlo\n",
    "\n",
    "Juan Sosa PhD\n",
    "\n",
    "Email jcsosam@unal.edu.co\n",
    "\n",
    "GitHub https://github.com/jstats1702\n",
    "\n",
    "Samuel Sánchez (Python y revisión R)\n",
    "\n",
    "Email ssanchezgu@unal.edu.co\n",
    "\n",
    "GitHub https://github.com/Samuel-col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "isolated-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuerde instalar todas las librerías aquí llamadas antes de corre esta celda. Ésto lo puede hacer con conda o pip.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "# from arviz import ess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-thomas",
   "metadata": {},
   "source": [
    "## 1 Motivación: modelo Normal con una distribución previa semi-conjugada\n",
    "\n",
    "En la mayoría de los casos **no es posible obtener directamente muestras la distribución posterior**.\n",
    "\n",
    "Considere especificar Su estado de información previo acerca de $\\theta$ de manera **independiente** de $\\sigma^2$ de forma que:\n",
    "$$\n",
    "p(\\theta,\\sigma^2) = p(\\theta)\\,p(\\sigma^2)\\,.\n",
    "$$\n",
    "Esta formulación es mas **flexible** porque no hay una restricción de dependencia a priori entre $\\theta$ y $\\sigma^2$.\n",
    "\n",
    "Asumiendo que las observaciones dadas en $\\boldsymbol{y} = (y_1,\\ldots,y_n)$ son intercambiables, bajo el **modelo Normal con una distribución previa semi-conjugada** se tiene que:\n",
    "\n",
    "- **Verosimilitud**:\n",
    "$$\n",
    "y_i\\mid\\theta,\\sigma^2 \\stackrel{\\text{iid}}{\\sim} \\textsf{N}(\\theta,\\sigma^2)\\,,\\qquad i=1,\\ldots,n.\n",
    "$$\n",
    "- **Previa**:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\theta   &\\sim \\textsf{N}(\\mu_0, \\tau^2_0) \\\\\n",
    "\\sigma^2 &\\sim \\textsf{GI}\\left(\\tfrac{\\nu_0}{2},\\tfrac{\\nu_0\\,\\sigma^2_0}{2}\\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- **Hiperparámetros**: $\\mu_0$, $\\tau^2_0$, $\\nu_0$, y $\\sigma^2_0$.\n",
    "\n",
    "En el caso de la previa conjugada (donde $\\tau_0^2$ es proporcional a $\\sigma^2$) se tiene que la distribución posterior de $\\sigma^2$ es Gamma Inversa. En este caso, **la distribución posterior de $\\sigma^2$ no sigue una distribución estándar conocida** de la cual se pueda obtener muestras directamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-reconstruction",
   "metadata": {},
   "source": [
    "### 1.1 Distribuciones condicionales completas\n",
    "\n",
    "El **muestreador de Gibbs** (*Gibbs sampler*) es un algoritmo iterativo que permite **obtener muestras dependientes** de la **distribución posterior** por medio de las **distribuciones condicionales completas**.\n",
    "\n",
    "Bajo esta especificación del modelo Normal, se demuestra que:\n",
    "\n",
    "- La distribución condicional completa de $\\theta$ es $\\theta\\mid\\sigma^2,\\boldsymbol{y}\\sim\\textsf{N}(\\mu_n,\\tau^2_n)$, donde\n",
    "$$\n",
    "\\mu_n = \\frac{\\frac{1}{\\tau^2_0}\\mu_0 + \\frac{n}{\\sigma^2}\\bar{y}}{\\frac{1}{\\tau^2_0} + \\frac{n}{\\sigma^2}} \\qquad\\text{y}\\qquad\\tau^2_n=\\frac{1}{\\frac{1}{\\tau^2_0} + \\frac{n}{\\sigma^2}}\\,.\n",
    "$$\n",
    "- La distribución condicional completa de $\\sigma^2$ es $\\sigma^2\\mid\\theta,\\boldsymbol{y}\\sim\\textsf{GI}\\left(\\tfrac{\\nu_n}{2},\\tfrac{\\nu_n\\,\\sigma^2_n}{2}\\right)$, donde\n",
    "$$\n",
    "\\nu_n = \\nu_0+n\\qquad\\text{y}\\qquad\\sigma^2_n = \\frac{1}{\\nu_n}\\left( \\nu_0\\sigma^2_0 + ns^2(\\theta) \\right)\\,.\n",
    "$$\n",
    "con $s^2(\\theta) = \\tfrac{1}{n}\\sum_{i=1}^n (y_i-\\theta)^2 = (n-1)s^2 + n(\\bar{y}-\\theta)^2$, el cual corresponde al estimardor insesgado de $\\sigma^2$ si $\\theta$ fuera conocido. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-kitchen",
   "metadata": {},
   "source": [
    "## 2 Muetreador de Gibbs\n",
    "\n",
    "Dado un **estado actual** de los parámetros del modelo $\\boldsymbol{\\theta}^{(b)} = \\left(\\theta^{(b)}, (\\sigma^2)^{(b)}\\right)$, se genera un nuevo estado $\\boldsymbol{\\theta}^{(b+1)}$ como sigue:\n",
    "\n",
    "1. Muestrear $\\theta^{(b+1)}\\sim p(\\theta\\mid(\\sigma^2)^{(b)}, \\boldsymbol{y})$.\n",
    "2. Muestrear $(\\sigma^2)^{(b+1)}\\sim p(\\sigma^2\\mid\\theta^{(b+1)}, \\boldsymbol{y})$.\n",
    "3. Establecer $\\boldsymbol{\\theta}^{(b+1)} = \\left(\\theta^{(b+1)}, (\\sigma^2)^{(b+1)}\\right)$. \n",
    "4. Repetir los pasos 1. a 3. hasta convergencia.\n",
    "\n",
    "Este algoritmo se denomina **muestreador de Gibbs** y genera una **secuencia dependiente** de parámetros $\\boldsymbol{\\theta}^{(1)},\\ldots,\\boldsymbol{\\theta}^{(B)}$ de la distribución posterior $p(\\theta,\\sigma^2\\mid \\boldsymbol{y})$. \n",
    "\n",
    "Como punto de partida, solo es necesario proporcionar un valor inicial para $\\sigma^2$. Usualmente este valor se muestra de la distribución previa correspondiente, esto es, $(\\sigma^2)^{(0)}\\sim\\textsf{IG}\\left(\\tfrac{\\nu_0}{2},\\tfrac{\\nu_0\\,\\sigma^2_0}{2}\\right)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-desire",
   "metadata": {},
   "source": [
    "### 2.1 Ejemplo: Muestreador de Gibbs para el modelo Normal\n",
    "\n",
    "En 1981, los biólogos W. L. Grogan y W. W. Wirth descubrieron en las selvas de \n",
    "Brasil dos nuevas variedades de un diminuto insecto picador llamado mosquito \n",
    "(*midge*). Llamaron a un tipo de mosquito Apf y al otro mosquito Af. \n",
    "Los biólogos descubrieron que el mosquito Apf es portador de una enfermedad \n",
    "debilitante que causa inflamación del cerebro cuando un humano está mordido \n",
    "por un mosquito infectado. Aunque la enfermedad rara vez es fatal, la \n",
    "discapacidad causada por la hinchazón puede ser permanente. La otra forma de \n",
    "mosquito, el Af, es bastante inofensiva y un valioso polinizador. \n",
    "En un esfuerzo por distinguir las dos variedades, los biólogos tomaron medidas \n",
    "en los mosquitos que capturaron. Este es un conjunto de datos valioso para \n",
    "probar métodos de clasificación.\n",
    "\n",
    "\n",
    "***Grogan Jr, W. L., & Wirth, W. W. (1981). A new American genus of predaceous midges related to Palpomyia and Bezzia (Diptera: Ceratopogonidae). Proceedings of the Biological Society of Washington., 94(4), 1279-1305.***\n",
    "\n",
    "<!--\n",
    "```{r, eval = TRUE, echo=FALSE, out.width=\"75%\", fig.pos = 'H', fig.align = 'center'}\n",
    "knitr::include_graphics(\"modelo_normal_midge.png\")\n",
    "```\n",
    "-->\n",
    "![](modelo_normal_midge.png)\n",
    "\n",
    "Considere los datos de la **longitud del ala en milímetros** ($y$) de $n=9$ miembros de \n",
    "la **especie Af de mosquitos**. A partir de estas nueve mediciones, se quiere \n",
    "hacer inferencia sobre la **media poblacional** $\\theta$. \n",
    "\n",
    "Otros estudios sugieren que \n",
    "la longitud de las alas suele ser de alrededor de 1.9 mm. Claramente, se tiene \n",
    "que las longitudes deben ser positivas, lo que implica que $\\theta > 0$.\n",
    "\n",
    "Los datos de Grogan y Wirth se encuentran disponibles en la librería `Flury` de R, pero esta librería no se encuentra disponible para versiones reciente de R.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-trinidad",
   "metadata": {},
   "source": [
    "#### Muestreador de Gibbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sustainable-bailey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8044444444444447"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datos\n",
    "y = np.array([1.64, 1.70, 1.72, 1.74, 1.82, 1.82, 1.82, 1.90, 2.08])\n",
    "# tamaño de la muestra\n",
    "n = len(y)\n",
    "# estadísticos\n",
    "mean_y = np.mean(y)\n",
    "mean_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fifty-galaxy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016877777777777787"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_y = np.var(y,ddof = 1)\n",
    "var_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "treated-segment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.240000000000002"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_y = np.sum(y)\n",
    "sum_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "convertible-macintosh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 % completado ... \n",
      "20.0 % completado ... \n",
      "30.0 % completado ... \n",
      "40.0 % completado ... \n",
      "50.0 % completado ... \n",
      "60.0 % completado ... \n",
      "70.0 % completado ... \n",
      "80.0 % completado ... \n",
      "90.0 % completado ... \n",
      "100.0 % completado ... \n"
     ]
    }
   ],
   "source": [
    "# hiperparametros\n",
    "mu0 = 1.9\n",
    "t20 = 0.5**2\n",
    "s20 = 0.01\n",
    "nu0 = 1\n",
    "# numero de muestras\n",
    "B = int(1e5)\n",
    "# matriz para almacenar las muestras\n",
    "PHI = []\n",
    "# mostrar anuncios cada 10% de las iteraciones\n",
    "ncat = np.floor(B/10)\n",
    "# ALGORITMO (muestreador de Gibbs)\n",
    "# 1. inicializar la cadena\n",
    "#    valor inicial: simular de la previa\n",
    "#    solo es necesario alguno de los valores\n",
    "np.random.seed(1234)\n",
    "theta = st.norm.rvs(mu0, scale = np.sqrt(t20), size = 1)\n",
    "isig2 = st.gamma.rvs(nu0/2, scale = 2/(nu0*s20), size = 1)\n",
    "PHI.append([theta,isig2])\n",
    "# 2. simular iterativamente de las distribuciones condicionales completas\n",
    "np.random.seed(1234)\n",
    "for b in range(1,B):\n",
    "    # 2.1 actualizar el valor de theta\n",
    "    t2n = 1/(1/t20 + n*isig2)\n",
    "    mun = (mu0/t20 + sum_y*isig2)*t2n\n",
    "    theta = st.norm.rvs(mun, scale = np.sqrt(t2n), size = 1)\n",
    "    # 2.2 actualizar el valor de sigma^2\n",
    "    nun = nu0 + n\n",
    "    s2n = (nu0*s20 + (n-1)*var_y + n*(mean_y - theta)**2)/nun\n",
    "    isig2 = st.gamma.rvs(nun/2, scale = 2/(nun*s2n), size = 1)\n",
    "    # 2.3 almacenar\n",
    "    PHI.append([theta,isig2])\n",
    "    # 2.4 progreso\n",
    "    if ((b+1)%ncat == 0):\n",
    "        print(100*np.round(b/B,1), \"% completado ... \")\n",
    "\n",
    "PHI = np.array(PHI)[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adjacent-stevens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.13571758, 38.3211147 ],\n",
       "       [ 1.8307793 , 33.55340142],\n",
       "       [ 1.84356794, 79.12729325],\n",
       "       [ 1.83709923, 44.2668239 ],\n",
       "       [ 1.78891335, 92.6829787 ],\n",
       "       [ 1.84462432, 89.67901834]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PHI[:6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "competitive-tiffany",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (Temp/ipykernel_3676/1004395330.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\JUANCA~1\\AppData\\Local\\Temp/ipykernel_3676/1004395330.py\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    plt.subplots_adjust(wspace = 0.3, hspac e =0.2)\u001b[0m\n\u001b[1;37m                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "# grafico del algoritmo\n",
    "# este gráfico no se acostumbra hacer en la práctica\n",
    "f, axes = plt.subplots(1, 2, figsize = (10,4.5), dpi = 300)\n",
    "plt.subplots_adjust(wspace = 0.3, hspac e =0.2)\n",
    "\n",
    "m1 = 15\n",
    "axes[0].plot(PHI[:m1,0], PHI[:m1,1], linewidth = 1, color = \"#dddddd\")\n",
    "for i in range(m1):\n",
    "    axes[0].text(PHI[i,0], PHI[i,1],i)\n",
    "axes[0].set_xlabel(r\"$\\theta$\")\n",
    "axes[0].set_ylabel(r\"$\\tilde{\\sigma}^2$\")\n",
    "    \n",
    "m1 = 100\n",
    "axes[1].plot(PHI[:m1,0], PHI[:m1,1], linewidth = 1, color = \"#dddddd\")\n",
    "for i in range(m1):\n",
    "    axes[1].text(PHI[i,0], PHI[i,1],i)\n",
    "axes[1].set_xlabel(r\"$\\theta$\")\n",
    "axes[1].set_ylabel(r\"$\\tilde{\\sigma}^2$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-pharmaceutical",
   "metadata": {},
   "source": [
    "#### Distribuciones posterior y marginales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(2, 2, figsize = (10,10),dpi = 300)\n",
    "plt.subplots_adjust(wspace = 0.3, hspace = 0.2)\n",
    "# distribución conjunta\n",
    "axes[0,0].scatter(PHI[:,0], PHI[:,1], marker = '.',s=0.01,color = \"#000000\")\n",
    "axes[0,0].set_xlabel(r\"$\\theta$\")\n",
    "axes[0,0].set_ylabel(r\"$\\tilde{\\sigma}^2$\")\n",
    "axes[0,0].set_ylim((0,225))\n",
    "# distribución conjunta\n",
    "axes[0,1].scatter(PHI[:,0],1/PHI[:,1], marker = '.', s = 0.01, color = \"#000000\")\n",
    "axes[0,1].set_xlabel(r\"$\\theta$\")\n",
    "axes[0,1].set_ylabel(r\"$\\sigma^2$\")\n",
    "axes[0,1].set_ylim((0,0.15))\n",
    "# theta\n",
    "theta = np.linspace(1.55,2.05,500)\n",
    "axes[1,0].plot(theta,st.gaussian_kde(PHI[:,0])(theta), color = 'black', linewidth = 1)\n",
    "axes[1,0].axhline(y = 0, color = '#c0c0c0', linewidth = 0.4)\n",
    "axes[1,0].set_xlabel(r\"$\\theta$\")\n",
    "axes[1,0].set_ylabel(r\"$p(\\theta|y)$\")\n",
    "# precision\n",
    "isig2 = np.linspace(0,250,500)\n",
    "axes[1,1].plot(isig2,st.gaussian_kde(PHI[:,1])(isig2), color = 'black', linewidth = 1)\n",
    "axes[1,1].axhline(y = 0, color = '#c0c0c0', linewidth = 0.4)\n",
    "axes[1,1].set_xlabel(r\"$\\tilde{\\sigma}^2$\")\n",
    "axes[1,1].set_ylabel(r\"$p(\\tilde{\\sigma}^2|y)$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-adrian",
   "metadata": {},
   "source": [
    "#### Inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intervalo de credibilidad\n",
    "# media\n",
    "tab = pd.DataFrame(data = [np.quantile(PHI[:,0], q = [0.025,0.5,0.975])], columns = [\"2.5%\", \"50%\",\"97.5%\"])\n",
    "round(tab,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-valuable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precision\n",
    "tab = pd.DataFrame(data = [np.quantile(PHI[:,1], q = [0.025,0.5,0.975])], columns = [\"2.5%\", \"50%\",\"97.5%\"])\n",
    "round(tab,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# desviacion estandar\n",
    "tab = pd.DataFrame(data = [np.quantile(1/np.sqrt(PHI[:,1]), q = [0.025,0.5,0.975])], columns = [\"2.5%\", \"50%\",\"97.5%\"])\n",
    "round(tab,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coeficiente de variación\n",
    "tab = pd.DataFrame(data = [np.quantile((1/np.sqrt(PHI[:,1]))/PHI[:,0], q = [0.025,0.5,0.975])], columns = [\"2.5%\", \"50%\",\"97.5%\"])\n",
    "round(tab,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(np.mean(PHI[:,0]>1.8), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-turtle",
   "metadata": {},
   "source": [
    "### 2.2 Algoritmo general\n",
    "\n",
    "Dado un **estado actual** de los parámetros del modelo $\\boldsymbol{\\theta}^{(b)} = \\left(\\theta_1^{(b)},\\ldots,\\theta_k^{(b)}\\right)$, se genera un nuevo estado $\\boldsymbol{\\theta}^{(b+1)}$ como sigue:\n",
    "\n",
    "1. Muestrear $\\theta_1^{(b+1)}\\sim p\\left(\\theta_1\\mid\\theta_2^{(b)},\\theta_3^{(b)},\\ldots,\\theta_k^{(b)}\\right)$.\n",
    "2. Muestrear $\\theta_2^{(b+1)}\\sim p\\left(\\theta_2\\mid\\theta_1^{(b+1)},\\theta_3^{(b)},\\ldots,\\theta_k^{(b)}\\right)$.\n",
    "3. Muestrear $\\theta_3^{(b+1)}\\sim p\\left(\\theta_3\\mid\\theta_1^{(b+1)},\\theta_2^{(b+1)},\\ldots,\\theta_k^{(b)}\\right)$.\n",
    "4. ...\n",
    "5. Muestrear $\\theta_k^{(b+1)}\\sim p\\left(\\theta_k\\mid\\theta_1^{(b+1)},\\theta_2^{(b+1)},\\ldots,\\theta_{k-1}^{(b+1)}\\right)$.\n",
    "6. Establecer $\\boldsymbol{\\theta}^{(b+1)} = \\left(\\theta_1^{(b+1)},\\ldots,\\theta_k^{(b+1)}\\right)$.\n",
    "7. Repetir los pasos 1. a 6. hasta convergencia.\n",
    "\n",
    "Este algoritmo genera una **secuencia dependiente** de parámetros $\\boldsymbol{\\theta}^{(1)},\\ldots,\\boldsymbol{\\theta}^{(B)}$ de la distribución posterior $p(\\theta_1,\\ldots,\\theta_k\\mid \\boldsymbol{y})$.\n",
    "\n",
    "Observe que $\\boldsymbol{\\theta}^{(b+1)}$ depende únicamente de $\\boldsymbol{\\theta}^{(b)}$ lo cual sugiere que $\\boldsymbol{\\theta}^{(1)},\\ldots,\\boldsymbol{\\theta}^{(B)}$ define una **cadena de Markov** (*Markov chain*).\n",
    "\n",
    "***Smith, A. F., & Roberts, G. O. (1993). Bayesian computation via the Gibbs sampler and related Markov chain Monte Carlo methods. Journal of the Royal Statistical Society: Series B (Methodological), 55(1), 3-23.***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-second",
   "metadata": {},
   "source": [
    "### 2.3 Cadenas de Markov\n",
    "\n",
    "Un **proceso estocástico** es una colección de variables aleatorias $\\{\\theta_t\\in S:t\\in T\\}$ para algún **espacio de estados** $S$ bien sea **discreto**, e.g., $\\{1,\\ldots,k\\}$, o continuo, e.g., $(-\\infty,\\infty)$, y un **conjunto de índices** $T$, bien sea **discreto**, e.g., $\\{0,1,\\ldots\\}$), o continuo, e.g., $[0,\\infty)$.\n",
    "\n",
    "Un proceso estocástico $\\{\\theta_t\\in S:t\\in T\\}$, con $T=\\{0,1,\\ldots\\}$, se denomina **cadena de Markov** si, para todo $A\\subset S$, se tiene que\n",
    "$$\n",
    "\\textsf{Pr}(\\theta_{t+1}\\in A\\mid \\theta_0,\\ldots,\\theta_t) = \\textsf{Pr}(\\theta_{t+1}\\in A\\mid\\theta_t)\\,.\n",
    "$$\n",
    "Una **cadena de Markov** es una clase particular de proceso estocástico cuyos **estados pasados y futuros son independientes dado el estado actual**, i.e., para caracterizar probabilísticamente hacia dónde se moverá la cadena a continuación, no necesita saber dónde ha estado, **solo debe considerar dónde está ahora**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emerging-semiconductor",
   "metadata": {},
   "source": [
    "#### Cadenas de Markov bien comportadas\n",
    "\n",
    "- Un estado $i$ se denomina **periódico** (*periodic*) con periodo $d$ si es visitado después de un número de pasos múltiplo de un entero $d > 1$.\n",
    "- Una cadena se denomina **aperiódica** (*aperiodic*) si para todos los estados se tiene que tal múltiplo no existe (i.e., $d=1$).\n",
    "- Una cadena se denomina **positiva recurrente** (*positive recurrent*) si para todos los estados $i$:\n",
    "    * Si el proceso comienza en un estado $i$ regresará a $i$ con probabilidad 1. \n",
    "    * El tiempo de espera medio para el regreso al estado $i$ es finito.\n",
    "      \n",
    "- Una cadena se denomina **ergódica** (*ergodic*) si es  **aperiódica** y **positiva recurrente**. \n",
    "\n",
    "#### Teorema Ergódico\n",
    "\n",
    "Las **cadenas de Markov ergódicas** poseen una **distribución estacionaria** única $\\pi(\\theta)$. Esta distribución caracteriza el **comportamiento que adopta la cadena después de evolucionar mucho tiempo**, independientemente de su estado inicial.\n",
    "\n",
    "**(Teorema Ergódico.)** Si una cadena de Markov $\\{\\theta_t\\in S:t\\in T\\}$ es **ergódica** y si $f$ es una función de valor real tal que $\\textsf{E}_\\pi|f(\\theta)|<\\infty$, entonces, con probabilidad 1, cuando $B\\rightarrow\\infty$ se tiene que\n",
    "$$\n",
    "\\frac{1}{B}\\sum_{b=1}^B f(\\theta_b) \\longrightarrow \\textsf{E}_{\\pi(\\theta)}(f(\\theta))\n",
    "$$\n",
    "donde el valor esperado de $f(\\theta)$ se toma respecto a la **distribución estacionaria** $\\pi(\\theta)$.\n",
    "\n",
    "El teorema **no dice nada** sobre tres aspectos prácticos fundamentales: \n",
    "\n",
    "- ¿Cuál debe ser el mejor punto de partida?\n",
    "- ¿Cuánto tiempo se debe esperar para lograr la estacionariedad?\n",
    "- ¿Cuánto tiempo se debe monitorear después de eso?\n",
    "\n",
    "Siempre que la distribución estacionaria sea la distribución posterior, se puede **aprender con precisión arbitraria** sobre **cualquier aspecto de la distribución posterior**. simplemente **esperando lo suficiente a que se logre la estacionariedad** y monitoreando a partir de entonces un período lo suficientemente largo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-specific",
   "metadata": {},
   "source": [
    "### 2.4 Resumen\n",
    "\n",
    "La idea es simular muestras de la distribución posterior $p(\\boldsymbol{\\theta}\\mid\\boldsymbol{y})$, por medio de una **cadena de Markov** con las siguientes características:\n",
    "\n",
    "- Debe tener el **mismo espacio de estados** que $\\boldsymbol{\\theta}$.\n",
    "- Debe ser **fácil de simular** (muestrear).\n",
    "- Debe tener a $p(\\boldsymbol{\\theta}\\mid\\boldsymbol{y})$ como **distribución estacionaria**.\n",
    "\n",
    "Se demuestra que una **cadena de Markov** construida a partir del **muestreador de Gibbs** es **ergódica** y tiene la **distribución posterior** como **distribución estacionaria**, sin importar el punto de partida de la cadena (algunos puntos de partida pueden ser mejores que otros). \n",
    "\n",
    "La secuencia $\\boldsymbol{\\theta}^{(1)},\\ldots,\\boldsymbol{\\theta}^{(B)}$ se puede usar tal y como se tratara de una muestra aleatoria de valores de $\\boldsymbol{\\theta}$ provenientes de la distribución posterior $p(\\boldsymbol{\\theta}\\mid y)$. Esto es,\n",
    "$$\n",
    "\\frac{1}{B} \\sum_{b=1}^{B} g(\\boldsymbol{\\theta}) \\longrightarrow \\textsf{E}[g(\\boldsymbol{\\theta}) \\mid \\boldsymbol{y}]=\\int_{\\Theta} g(\\boldsymbol{\\theta})\\, p(\\boldsymbol{\\theta} \\mid \\boldsymbol{y})\\,\\textsf{d}\\boldsymbol{\\theta}\\qquad\\text{cuando}\\qquad B\\rightarrow \\infty\\,.\n",
    "$$\n",
    "\n",
    "El punto de partida $\\boldsymbol{\\theta}^{(0)}$ es arbitrario y usualmente se muestrea de la distribución previa.\n",
    "\n",
    "El **muestreador de Gibbs** hace parte de un conjunto de técnicas de aproximación denominadas **cadenas de Markov de Monte Carlo** (*Markov Chain Monte Carlo*, MCMC).\n",
    "\n",
    "Los métodos de MCMC constituyen **técnicas de aproximación numérica**, **no son modelos**, **no generan más información** además de la contenida en $\\boldsymbol{y}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-roberts",
   "metadata": {},
   "source": [
    "### 2.5 Diagnósticos de convergencia (estacionariedad)\n",
    "\n",
    "**Preguntas:**\n",
    "\n",
    "- ¿Cual debe ser el punto de partida?\n",
    "- ¿La cadena alcanzo el equilibrio?\n",
    "- Una vez alcanzado el equilibrio, ¿cuánto más se debe monitorear para lograr buenas aproximaciones?\n",
    "\n",
    "Para que las **aproximaciones a las cantidades posteriores sean precisas**, se necesita que la distribución empírica de $\\boldsymbol{\\theta}^{(1)},\\ldots,\\boldsymbol{\\theta}^{(B)}$ esté lo suficientemente cerca de $p(\\boldsymbol{\\theta}\\mid y)$.\n",
    "\n",
    "El muestreador de Gibbs produce **muestras que eventualmente van a converger** a la distribución objetivo, pero en algunos casos la **convergencia puede ser lenta** debido a la **autocorrelación** de los parámetros.\n",
    "\n",
    "Es usual pensar en la secuencia $\\boldsymbol{\\theta}^{(1)},\\ldots,\\boldsymbol{\\theta}^{(B)}$ como la **trayectoria de una partícula** $\\boldsymbol{\\theta}$ moviéndose a lo largo del espacio de parámetros $\\Theta$.\n",
    "\n",
    "No es posible estar absolutamente seguro que la cadena ha convergido. **Solo se puede saber si no lo ha hecho.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-assist",
   "metadata": {},
   "source": [
    "\n",
    "#### Serie\n",
    "\n",
    "Permiten chequear **estacionariedad** (muestras de una parte de la cadena tienen una distribución similar a muestras de otra parte de la cadena). \n",
    "\n",
    "También permiten ver si la cadena está **mezclando** bien o no (en simulación de Monte Carlo la partícula se mueve libremente a cualquier región del espacio de parámetros, lo cual significa cero autocorrelación).\n",
    "\n",
    "Para resolver problemas de estacionariedad se recomienda **correr la cadena con más iteraciones**.\n",
    "\n",
    "#### Autocorrelación\n",
    "\n",
    "La función de autocorrelación está dada por\n",
    "$$\n",
    "\\operatorname{acf}_{t}(\\theta)=\\frac{\\frac{1}{B-t} \\sum_{b=1}^{B-t}\\left(\\theta^{(b)}-\\bar{\\theta}\\right)\\left(\\theta^{(b+t)}-\\bar{\\theta}\\right)}{\\frac{1}{B-1} \\sum_{b=1}^{B}\\left(\\theta^{(b)}-\\bar{\\theta}\\right)^{2}}\\qquad\\text{donde}\\qquad\\bar{\\theta} = \\frac{1}{B}\\sum_{b=1}^B \\theta^{(b)}\\,.\n",
    "$$\n",
    "Entre **mayor sea la autocorrelación**, se necesitan **más muestras** para obtener la precisión deseada.\n",
    "\n",
    "Para resolver problemas de correlación se recomienda **adelgazar la cadena sistemáticamente** (muestreo sistemático de la cadena).\n",
    "\n",
    "#### Tamaño efectivo de muestra\n",
    "\n",
    "Las cadenas suelen estar autocorrelacionadas positivamente, por lo tanto contienen menos información que una secuencia de muestras iid de la distribución objetivo.\n",
    "\n",
    "Se quiere establecer la cantidad de muestras iid que contendrían la misma información de la cadena.\n",
    "$$\n",
    "n_{\\text{eff}}(\\theta) = \\frac{B}{1 + 2\\sum_{t=1}^\\infty \\operatorname{acf}_{t}(\\theta)}\n",
    "$$\n",
    "donde $\\rho_t$ es la autocorrelación en el lag $t$. Comunmente, la suma se hace hasta que $\\text{acf}_{t-1} + \\text{acf}_t < 0$.\n",
    "\n",
    "### Error estándar de Monte Carlo\n",
    "\n",
    "El error estándar de Monte Carlo hace referencia a la variabilidad (desviación estándar) del promedio muestral respecto al tamaño efectivo de muestra:\n",
    "$$\n",
    "\\textsf{EMC}(\\hat\\theta) = \\frac{\\textsf{DE}(\\hat\\theta)}{\\sqrt{n_{\\text{eff}}(\\theta)}}\n",
    "$$\n",
    "donde $\\textsf{DE}(\\hat\\theta) = \\sqrt{\\frac{1}{B-1}\\sum_{b=1}^B (\\theta^{(b))}-\\bar\\theta)^2}$ es la desviación estándar muestral de $\\hat\\theta$ y $n_{\\text{eff}}$ es el tamaño efectivo de la muestra asociada con la cadena de $\\theta$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-density",
   "metadata": {},
   "source": [
    "### 2.6 Ejemplo: Diagnósticos de convergencia\n",
    "\n",
    "#### Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cadenas\n",
    "f, axes = plt.subplots(2, 1, figsize = (10,10), dpi = 300)\n",
    "plt.subplots_adjust(wspace = 0.3, hspace = 0.2)\n",
    "\n",
    "axes[0].scatter(range(B-10), PHI[10:,0], marker = '.', s = 0.1, color = \"black\")\n",
    "axes[0].set_xlabel(\"Iteración\")\n",
    "axes[0].set_ylabel(r\"$\\theta$\")\n",
    "\n",
    "axes[1].scatter(range(B-10), 1/PHI[10:,1], marker = '.', s = 0.1, color = \"black\")\n",
    "axes[1].set_xlabel(\"Iteración\")\n",
    "axes[1].set_ylabel(r\"$\\sigma^2$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-affiliation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-verosimilitud\n",
    "LL = []\n",
    "for i in range(B):\n",
    "    LL.append(np.sum(st.norm.logpdf(y, loc = PHI[i,0], scale = np.sqrt(1/PHI[i,1]))))\n",
    "# cadena\n",
    "fig = plt.figure(figsize = (8,3), dpi = 800)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(range(B-10), LL[10:], marker = '.', s = 0.1, color = \"black\")\n",
    "ax.set_xlabel(\"Iteración\")\n",
    "ax.set_ylabel(\"Log-verosimilitud\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-sydney",
   "metadata": {},
   "source": [
    "#### Autocorrelación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autocorrelacion\n",
    "f, axes = plt.subplots(1, 2, figsize = (10,4.6), dpi = 300)\n",
    "plt.subplots_adjust(wspace = 0.3, hspace = 0.2)\n",
    "plot_acf(PHI[:,0], lags = 50, ax = axes[0], marker = '', adjusted = True)\n",
    "axes[0].set_title(r\"$\\theta$\")\n",
    "axes[0].set_ylim([-0.03,1.03])\n",
    "plot_acf(1/PHI[:,1], lags = 50, ax = axes[1], marker = '', adjusted = True)\n",
    "axes[1].set_title(r\"$\\sigma^2$\")\n",
    "axes[1].set_ylim([-0.03,1.03])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-special",
   "metadata": {},
   "source": [
    "#### Tamaño efectivo de muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño efectivo de la muestra\n",
    "# https://arviz-devs.github.io/arviz/api/generated/arviz.ess.html\n",
    "# tem = [ess(PHI[:,0]),ess(PHI[:,1])]\n",
    "# tab = pd.DataFrame(data = [tem], columns = [r\"$\\theta$\", r\"$\\tilde\\sigma^2$\"])\n",
    "# round(tab,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-repair",
   "metadata": {},
   "source": [
    "#### Error estándar de Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# error estándar de Monte Carlo\n",
    "# ee = [np.std(PHI[:,i])/np.sqrt(ess(PHI[:,i])) for i in range(2)]\n",
    "# tab = pd.DataFrame(data = [ee], columns = [r\"$\\theta$\", r\"$\\tilde\\sigma^2$\"])\n",
    "# round(tab,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-federal",
   "metadata": {},
   "source": [
    "Ver https://cran.r-project.org/web/packages/bayesplot/vignettes/visual-mcmc-diagnostics.html y https://arviz-devs.github.io/arviz/api/diagnostics.html para más diagnósticos. para más diagnosticos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-liabilities",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "<img src=\"Hoffcoverbook.jpg\" width = 250 />\n",
    "\n",
    "<img src=\"Gelmancoverbook.png\" width = 250 />\n",
    "\n",
    "<img src=\"Reichcoverbook.jpg\" width = 250 />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
